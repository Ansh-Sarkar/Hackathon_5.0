{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "import numpy as np\n",
    "import glob\n",
    "import os \n",
    "import cv2\n",
    "\n",
    "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### Data cleanup and loading #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_image=[]\n",
    "train_path='E://handy//ml1//train'\n",
    "fps=5\n",
    "train_videos=os.listdir('E://handy//ml1//train//training_videos')\n",
    "train_images_path=train_path+'/frames'\n",
    "try:\n",
    "    os.makedirs(train_images_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "    \n",
    "def store_inarray(image_path):\n",
    "    image=load_img(image_path)\n",
    "    image=img_to_array(image)\n",
    "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\n",
    "    gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\n",
    "    store_image.append(gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in train_videos:\n",
    "    os.system( 'ffmpeg -i E://handy//ml1//train//training_videos//{} -r 1/{}  E://handy//ml1//train//frames/%03d.jpg'.format(video,fps))\n",
    "    images=os.listdir(train_images_path)\n",
    "    for image in images:\n",
    "        image_path=train_images_path + '/' + image\n",
    "        store_inarray(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def rotate(image, angle=90, scale=1.0):\n",
    "        w = image.shape[1]\n",
    "        h = image.shape[0]\n",
    "        M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
    "        image = cv2.warpAffine(image,M,(w,h))\n",
    "        \n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        image = cv2.dilate(image, kernel, iterations = 1)\n",
    "        image = cv2.erode(image, kernel, iterations = 1)\n",
    "        return image\n",
    "def flip(image, vflip=False, hflip=False):\n",
    "        if hflip or vflip:\n",
    "            if hflip and vflip:\n",
    "                c = -1\n",
    "            else:\n",
    "                c = 0 if vflip else 1\n",
    "            image = cv2.flip(image, flipCode=c)\n",
    "        return image \n",
    "    \n",
    "def image_agumentation:  \n",
    "    images=os.listdir(train_images_path)\n",
    "    for image in images:\n",
    "            image_path=train_images_path + '/' + image\n",
    "            img = mpimg.imread(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            plt.imshow(gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "            plt.show()\n",
    "            img_flip = flip(gray, vflip=True, hflip=False)\n",
    "            img_rot = rotate(img_flip)\n",
    "            imgplot = plt.imshow(img_rot, cmap=\"gray\", vmin=0, vmax=255)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### model training #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_image=np.array(store_image)\n",
    "a,b,c=store_image.shape\n",
    "\n",
    "store_image.resize(b,c,a)\n",
    "store_image=(store_image-store_image.mean())/(store_image.std())\n",
    "store_image=np.clip(store_image,0,1)\n",
    "np.save('training.npy',store_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stae_model=Sequential()\n",
    "\n",
    "stae_model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',input_shape=(227,227,10,1),activation='tanh'))\n",
    "stae_model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
    "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\n",
    "stae_model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5))\n",
    "stae_model.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\n",
    "stae_model.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='tanh'))\n",
    "\n",
    "stae_model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=np.load('training1.npy')\n",
    "frames=training_data.shape[2]\n",
    "frames=frames-frames%10\n",
    "\n",
    "training_data=training_data[:,:,:frames]\n",
    "training_data=training_data.reshape(-1,227,227,10)\n",
    "training_data=np.expand_dims(training_data,axis=4)\n",
    "target_data=training_data.copy()\n",
    "\n",
    "epochs=10\n",
    "batch_size=1\n",
    "\n",
    "callback_save = ModelCheckpoint(\"Xmodel.h5\", monitor=\"mean_squared_error\", save_best_only=True)\n",
    "\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "stae_model.fit(training_data,target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save,callback_early_stopping])\n",
    "stae_model.save(\"Xmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"Xmodel.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from firebase import firebase\n",
    "import cv2\n",
    "import numpy as np \n",
    "import argparse\n",
    "from PIL import Image\n",
    "import imutils\n",
    "\n",
    "sample_anamoly_video1 = \"C://Users//Utkarsh//Desktop//1_Trim.mp4\"\n",
    "sample_anamoly_video2 = \"C://Users//Utkarsh//Desktop//2.mp4\"\n",
    "sample_normal_video = \"C://Users//Utkarsh//Desktop//01.avi\"\n",
    "\n",
    "\n",
    "\n",
    "def mean_squared_loss(x1,x2):\n",
    "    difference = x1-x2\n",
    "    a,b,c,d,e = difference.shape\n",
    "    n_samples = a*b*c*d*e\n",
    "    sq_difference = difference**2\n",
    "    Sum = sq_difference.sum()\n",
    "    distance = np.sqrt(Sum)\n",
    "    mean_distance = distance/n_samples\n",
    "\n",
    "    return mean_distance\n",
    "\n",
    "def smart_cam(sample_video):\n",
    "    threshold = 0.00057\n",
    "    model = load_model(\"Xmodel.h5\")\n",
    "\n",
    "    cap = cv2.VideoCapture(sample_video)\n",
    "    print(\"SMART SURVAILLANCE: {}\".format(cap.isOpened()))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        imagedump = []\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        if frame.any()== None:\n",
    "            break\n",
    "\n",
    "        for i in range(10):\n",
    "            _, frame = cap.read()\n",
    "            image = imutils.resize(frame,width=700,height=600)\n",
    "\n",
    "            frame = cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA)\n",
    "            gray = 0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\n",
    "            gray = (gray-gray.mean())/gray.std()\n",
    "            gray = np.clip(gray,0,1)\n",
    "            imagedump.append(gray)\n",
    "\n",
    "        imagedump = np.array(imagedump)\n",
    "\n",
    "        imagedump.resize(227,227,10)\n",
    "        imagedump = np.expand_dims(imagedump,axis=0)\n",
    "        imagedump = np.expand_dims(imagedump,axis=4)\n",
    "\n",
    "        output = model.predict(imagedump)\n",
    "\n",
    "        loss = mean_squared_loss(imagedump,output)\n",
    "#         print(loss)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "        print(loss)\n",
    "        if loss > threshold:\n",
    "            cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\n",
    "            if loss < 0.00058 and loss > 0.00056: \n",
    "                cv2.putText(image,\"Severity: Moderate\",(100,120),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "            elif loss > 0.00062:\n",
    "                cv2.putText(image,\"Severity: High\",(100,120),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "\n",
    "        cv2.imshow(\"video\",image)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "smart_cam(sample_normal_video)\n",
    "smart_cam(sample_anamoly_video1)\n",
    "smart_cam(sample_anamoly_video2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
